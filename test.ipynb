{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/space/hotel/bachn/ssms/BCP/code/test_ACDC.py:12: DeprecationWarning: Please import `zoom` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  from scipy.ndimage.interpolation import zoom\n",
      "init weight from ../model/BCP/ACDC_BCP_original_7_labeled/self_train/unet_best_model.pth\n",
      "100%|███████████████████████████████████████████| 40/40 [00:51<00:00,  1.28s/it]\n",
      "[array([0.88603533, 0.80243652, 1.83100243, 0.58389773]), array([0.86503377, 0.76428942, 5.68124669, 1.14336653]), array([0.92640091, 0.86811798, 5.55623006, 1.16733781])]\n",
      "[0.89249    0.81161464 4.35615973 0.96486736]\n"
     ]
    }
   ],
   "source": [
    "!python test_ACDC.py --exp BCP_original --gpu 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2191345/279104768.py:23: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following files will be zipped:\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient066_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient081_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient075_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient024_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient008_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient007_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient059_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient065_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient083_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient064_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient093_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient080_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient068_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient013_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient052_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient033_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient001_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient084_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient022_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient011_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient084_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient001_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient011_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient022_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient013_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient052_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient033_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient083_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient064_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient093_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient068_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient080_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient066_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient081_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient075_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient024_frame02.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient065_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient008_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient007_frame01.jpg\n",
      "../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions/visualized/patient059_frame02.jpg\n",
      "All files zipped successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "with open('../data/ACDC/test.list', 'r') as f:\n",
    "    test = f.readlines()\n",
    "test = [item.replace('\\n', '') for item in test]\n",
    "\n",
    "file_name_list = []\n",
    "# List of file names\n",
    "exp = '../model/BCP/ACDC_BCP_original_7_labeled/unet_predictions'\n",
    "for sample in test:\n",
    "    file_name = sample\n",
    "    file_names = [f'{exp}/{file_name}_img.nii.gz', f'{exp}/{file_name}_gt.nii.gz', f'{exp}/{file_name}_pred.nii.gz']\n",
    "    file_name_list.append([sample, file_names])\n",
    "\n",
    "vis_dir = f'{exp}/visualized'\n",
    "os.makedirs(vis_dir, exist_ok=True)\n",
    "\n",
    "for sample, file_names in file_name_list:\n",
    "    plt.clf()\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    for i, file_name in enumerate(file_names):\n",
    "        # Load the .nii.gz file\n",
    "        img = nib.load(file_name)\n",
    "        data = img.get_fdata()\n",
    "\n",
    "        # Display a middle slice\n",
    "        slice_index = data.shape[2] // 2\n",
    "        axes[i].imshow(data[:, :, slice_index], cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f'{vis_dir}/{sample}.jpg')\n",
    "    \n",
    "plt.close()\n",
    "\n",
    "# Zip file\n",
    "from zipfile import ZipFile \n",
    "import os \n",
    "  \n",
    "def get_all_file_paths(directory): \n",
    "  \n",
    "    # initializing empty file paths list \n",
    "    file_paths = [] \n",
    "  \n",
    "    # crawling through directory and subdirectories \n",
    "    for root, directories, files in os.walk(directory): \n",
    "        for filename in files: \n",
    "            # join the two strings in order to form the full filepath. \n",
    "            filepath = os.path.join(root, filename) \n",
    "            file_paths.append(filepath) \n",
    "  \n",
    "    # returning all file paths \n",
    "    return file_paths \n",
    "\n",
    "directory = vis_dir\n",
    "  \n",
    "# calling function to get all file paths in the directory \n",
    "file_paths = get_all_file_paths(directory) \n",
    "  \n",
    "# printing the list of all files to be zipped \n",
    "print('Following files will be zipped:') \n",
    "for file_name in file_paths: \n",
    "    print(file_name) \n",
    "  \n",
    "# writing files to a zipfile \n",
    "with ZipFile(f'{vis_dir}/pred.zip','w') as zip: \n",
    "    # writing each file one by one \n",
    "    for file in file_paths: \n",
    "        zip.write(file) \n",
    "  \n",
    "print('All files zipped successfully!')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_847635/3873940199.py:12: DeprecationWarning: Please import `zoom` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  from scipy.ndimage.interpolation import zoom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init weight from ../model/BCP/ACDC_BCP_imba2_7_labeled/self_train/unet_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8174, device='cuda:0')\n",
      "tensor(0.9732, device='cuda:0')\n",
      "tensor(0.9770, device='cuda:0')\n",
      "tensor(0.9630, device='cuda:0')\n",
      "tensor(0.9321, device='cuda:0')\n",
      "tensor(0.9465, device='cuda:0')\n",
      "tensor(0.9474, device='cuda:0')\n",
      "tensor(0.9087, device='cuda:0')\n",
      "tensor(nan, device='cuda:0')\n",
      "tensor(0.6907, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.891876  , 0.80485216, 1.        , 0.42344789]), array([0.84015167, 0.72436339, 1.41421356, 0.60073945]), array([0.94519876, 0.89609181, 1.        , 0.33410516])]\n",
      "[0.89240881 0.80843579 1.13807119 0.45276417]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import h5py\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import torch\n",
    "from medpy import metric\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from tqdm import tqdm   \n",
    "\n",
    "from networks.net_factory import net_factory\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--root_path', type=str, default='../data/ACDC', help='Name of Experiment')\n",
    "parser.add_argument('--exp', type=str, default='BCP_original', help='experiment_name')\n",
    "parser.add_argument('--model', type=str, default='unet', help='model_name')\n",
    "parser.add_argument('--num_classes', type=int,  default=4, help='output channel of network')\n",
    "parser.add_argument('--labelnum', type=int, default=7, help='labeled data')\n",
    "parser.add_argument('--stage_name', type=str, default='self_train', help='self or pre')\n",
    "\n",
    "\n",
    "def calculate_metric_percase(pred, gt):\n",
    "    pred[pred > 0] = 1\n",
    "    gt[gt > 0] = 1\n",
    "    dice = metric.binary.dc(pred, gt)\n",
    "    jc = metric.binary.jc(pred, gt)\n",
    "    asd = metric.binary.asd(pred, gt)\n",
    "    hd95 = metric.binary.hd95(pred, gt)\n",
    "    return dice, jc, hd95, asd\n",
    "\n",
    "\n",
    "def test_single_volume(case, net):\n",
    "    h5f = h5py.File(root_path + \"/data/{}.h5\".format(case), 'r')\n",
    "    image = h5f['image'][:]\n",
    "    label = h5f['label'][:]\n",
    "    prediction = np.zeros_like(label)\n",
    "    for ind in range(image.shape[0]):\n",
    "        slice = image[ind, :, :]\n",
    "        x, y = slice.shape[0], slice.shape[1]\n",
    "        slice = zoom(slice, (256 / x, 256 / y), order=0)\n",
    "        input = torch.from_numpy(slice).unsqueeze(0).unsqueeze(0).float().cuda()\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            out_main = net(input)\n",
    "            if len(out_main)>1:\n",
    "                out_main=out_main[0]\n",
    "            \n",
    "            idx = 1\n",
    "            probs = torch.softmax(out_main, dim=1)\n",
    "            max_values, indices = torch.max(probs, dim=1)\n",
    "            mean = (max_values * (indices==idx)).sum() / (indices == idx).sum()\n",
    "            print(mean)\n",
    "            \n",
    "            out = torch.argmax(probs, dim=1).squeeze(0)\n",
    "            out = out.cpu().detach().numpy()\n",
    "            pred = zoom(out, (x / 256, y / 256), order=0)\n",
    "            prediction[ind] = pred\n",
    "    if np.sum(prediction == 1)==0:\n",
    "        first_metric = 0,0,0,0\n",
    "    else:\n",
    "        first_metric = calculate_metric_percase(prediction == 1, label == 1)\n",
    "\n",
    "    if np.sum(prediction == 2)==0:\n",
    "        second_metric = 0,0,0,0\n",
    "    else:\n",
    "        second_metric = calculate_metric_percase(prediction == 2, label == 2)\n",
    "\n",
    "    if np.sum(prediction == 3)==0:\n",
    "        third_metric = 0,0,0,0\n",
    "    else:\n",
    "        third_metric = calculate_metric_percase(prediction == 3, label == 3)\n",
    "    return first_metric, second_metric, third_metric\n",
    "\n",
    "\n",
    "def Inference():\n",
    "    with open(root_path + '/test.list', 'r') as f:\n",
    "        image_list = f.readlines()\n",
    "    image_list = sorted([item.replace('\\n', '').split(\".\")[0] for item in image_list])\n",
    "    snapshot_path = \"../model/BCP/ACDC_{}_{}_labeled/{}\".format(exp, labelnum, stage_name)\n",
    "    net = net_factory(net_type=model, in_chns=1, class_num=num_classes)\n",
    "    save_model_path = os.path.join(snapshot_path, '{}_best_model.pth'.format(model))\n",
    "    net.load_state_dict(torch.load(save_model_path))\n",
    "\n",
    "    print(\"init weight from {}\".format(save_model_path))\n",
    "    net.eval()\n",
    "\n",
    "    first_total = 0.0\n",
    "    second_total = 0.0\n",
    "    third_total = 0.0\n",
    "    img_count = 0\n",
    "    for case in tqdm(image_list):\n",
    "        first_metric, second_metric, third_metric = test_single_volume(case, net)\n",
    "        first_total += np.asarray(first_metric)\n",
    "        second_total += np.asarray(second_metric)\n",
    "        third_total += np.asarray(third_metric)\n",
    "        img_count += 1\n",
    "        break\n",
    "    avg_metric = [first_total / img_count, second_total / img_count, third_total / img_count]\n",
    "    return avg_metric\n",
    "\n",
    "\n",
    "root_path = '../data/ACDC'\n",
    "exp = 'BCP_imba2'\n",
    "model = 'unet'\n",
    "num_classes = 4\n",
    "labelnum = 7\n",
    "stage_name = 'self_train'\n",
    "metric = Inference()\n",
    "print(metric)\n",
    "print((metric[0]+metric[1]+metric[2])/3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
